{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHxbelG9LXv3",
        "outputId": "6dee26df-d73f-43ea-c914-aed5739a524f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.20.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv) (3.20.3)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv) (4.5.1)\n",
            "Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 56.4 MB/s eta 0:00:00\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 469.0/469.0 kB 27.3 MB/s eta 0:00:00\n",
            "Installing collected packages: distlib, virtualenv\n",
            "Successfully installed distlib-0.4.0 virtualenv-20.36.1\n",
            "created virtual environment CPython3.12.12.final.0-64 in 323ms\n",
            "  creator CPython3Posix(dest=/content/ads_venv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: pip==25.3\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n",
            "Requirement already satisfied: pip in ./ads_venv/lib/python3.12/site-packages (25.3)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-80.10.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting packaging>=24.0 (from wheel)\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading setuptools-80.10.2-py3-none-any.whl (1.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 13.6 MB/s  0:00:00\n",
            "Downloading wheel-0.46.3-py3-none-any.whl (30 kB)\n",
            "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Installing collected packages: setuptools, packaging, wheel\n",
            "\n",
            "Successfully installed packaging-26.0 setuptools-80.10.2 wheel-0.46.3\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "python3 -m pip install -U virtualenv\n",
        "rm -rf /content/ads_venv\n",
        "python3 -m virtualenv /content/ads_venv\n",
        "\n",
        "/content/ads_venv/bin/python -m pip install -U pip setuptools wheel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "/content/ads_venv/bin/python -m pip install -U \\\n",
        "  streamlit \\\n",
        "  langchain langchain-core langchain-google-genai google-generativeai \\\n",
        "  \"e2b-code-interpreter==2.4.1\" \\\n",
        "  pandas matplotlib seaborn \\\n",
        "  \"pillow<12\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g-Na_GALdqE",
        "outputId": "1e74c8fb-6980-4e93-de5c-8658811ba4b7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.53.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.2.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-1.2.7-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting e2b-code-interpreter==2.4.1\n",
            "  Downloading e2b_code_interpreter-2.4.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pillow<12\n",
            "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting attrs>=21.3.0 (from e2b-code-interpreter==2.4.1)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting e2b<3.0.0,>=2.7.0 (from e2b-code-interpreter==2.4.1)\n",
            "  Downloading e2b-2.12.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting httpx<1.0.0,>=0.20.0 (from e2b-code-interpreter==2.4.1)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting dockerfile-parse<3.0.0,>=2.0.1 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading dockerfile_parse-2.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting httpcore<2.0.0,>=1.0.5 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=24.1 in ./ads_venv/lib/python3.12/site-packages (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1) (26.0)\n",
            "Collecting protobuf>=4.21.0 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading protobuf-6.33.4-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting python-dateutil>=2.8.2 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting rich>=14.0.0 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading rich-14.3.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting typing-extensions>=4.1.0 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting wcmatch<11.0,>=10.1 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading wcmatch-10.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting certifi (from httpcore<2.0.0,>=1.0.5->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting h11>=0.16 (from httpcore<2.0.0,>=1.0.5->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting anyio (from httpx<1.0.0,>=0.20.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting idna (from httpx<1.0.0,>=0.20.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting bracex>=2.1.1 (from wcmatch<11.0,>=10.1->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading bracex-2.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
            "  Downloading altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cachetools<7,>=5.5 (from streamlit)\n",
            "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting click<9,>=7.0 (from streamlit)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting numpy<3,>=1.23 (from streamlit)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting pyarrow>=7.0 (from streamlit)\n",
            "  Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2.27 (from streamlit)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting toml<2,>=0.10.1 (from streamlit)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting tornado!=6.5.0,<7,>=6.0.3 (from streamlit)\n",
            "  Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading narwhals-2.15.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.7 (from langchain)\n",
            "  Downloading langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
            "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core)\n",
            "  Downloading langsmith-0.6.6-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting packaging>=24.1 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core)\n",
            "  Downloading uuid_utils-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading ormsgpack-1.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading orjson-3.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core)\n",
            "  Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-genai<2.0.0,>=1.56.0 (from langchain-google-genai)\n",
            "  Downloading google_genai-1.60.0-py3-none-any.whl.metadata (53 kB)\n",
            "Collecting google-auth<3.0.0,>=2.47.0 (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting distro<2,>=1.7.0 (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting sniffio (from google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting cryptography>=38.0.3 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading cryptography-46.0.4-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting google-api-core (from google-generativeai)\n",
            "  Downloading google_api_core-2.29.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-api-python-client (from google-generativeai)\n",
            "  Downloading google_api_python_client-2.188.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tqdm (from google-generativeai)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading proto_plus-1.27.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf>=4.21.0 (from e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
            "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (114 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib)\n",
            "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting cffi>=2.0.0 (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pycparser (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai)\n",
            "  Downloading pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.25.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading rpds_py-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=14.0.0->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=14.0.0->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=14.0.0->e2b<3.0.0,>=2.7.0->e2b-code-interpreter==2.4.1)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading httplib2-0.31.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
            "  Downloading google_auth_httplib2-0.3.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
            "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading e2b_code_interpreter-2.4.1-py3-none-any.whl (13 kB)\n",
            "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 32.4 MB/s  0:00:00\n",
            "Downloading e2b-2.12.1-py3-none-any.whl (220 kB)\n",
            "Downloading dockerfile_parse-2.0.1-py2.py3-none-any.whl (14 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading wcmatch-10.1-py3-none-any.whl (39 kB)\n",
            "Downloading streamlit-1.53.1-py3-none-any.whl (9.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 78.3 MB/s  0:00:00\n",
            "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 126.3 MB/s  0:00:00\n",
            "Downloading altair-6.0.0-py3-none-any.whl (795 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 795.4/795.4 kB 46.3 MB/s  0:00:00\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 181.7 MB/s  0:00:00\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 113.9 MB/s  0:00:00\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading tornado-6.5.4-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "Downloading langchain-1.2.7-py3-none-any.whl (108 kB)\n",
            "Downloading langchain_core-1.2.7-py3-none-any.whl (490 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langgraph-1.0.7-py3-none-any.whl (157 kB)\n",
            "Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
            "Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
            "Downloading langgraph_sdk-0.3.3-py3-none-any.whl (67 kB)\n",
            "Downloading langsmith-0.6.6-py3-none-any.whl (308 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
            "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 113.8 MB/s  0:00:00\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 807.9/807.9 kB 49.8 MB/s  0:00:00\n",
            "Downloading uuid_utils-0.14.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "Downloading langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_genai-1.60.0-py3-none-any.whl (719 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 719.4/719.4 kB 42.7 MB/s  0:00:00\n",
            "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
            "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Downloading google_generativeai-0.8.6-py3-none-any.whl (155 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 61.6 MB/s  0:00:00\n",
            "Downloading google_api_core-2.29.0-py3-none-any.whl (173 kB)\n",
            "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
            "Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 179.0 MB/s  0:00:00\n",
            "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
            "Downloading proto_plus-1.27.0-py3-none-any.whl (50 kB)\n",
            "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Downloading matplotlib-3.10.8-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 179.7 MB/s  0:00:00\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading bracex-2.6-py3-none-any.whl (11 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
            "Downloading cryptography-46.0.4-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 149.2 MB/s  0:00:00\n",
            "Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (5.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 148.2 MB/s  0:00:00\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 75.7 MB/s  0:00:00\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading narwhals-2.15.0-py3-none-any.whl (432 kB)\n",
            "Downloading orjson-3.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
            "Downloading ormsgpack-1.12.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "Downloading pyarrow-23.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.6/47.6 MB 47.2 MB/s  0:00:01\n",
            "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Downloading rich-14.3.1-py3-none-any.whl (309 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 78.8 MB/s  0:00:00\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading rpds_py-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (394 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
            "Downloading zstandard-0.25.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 131.1 MB/s  0:00:00\n",
            "Downloading google_api_python_client-2.188.0-py3-none-any.whl (14.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.9/14.9 MB 168.3 MB/s  0:00:00\n",
            "Downloading google_auth_httplib2-0.3.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading httplib2-0.31.2-py3-none-any.whl (91 kB)\n",
            "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading pycparser-3.0-py3-none-any.whl (48 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: pytz, filetype, zstandard, xxhash, websockets, watchdog, uuid-utils, urllib3, uritemplate, tzdata, typing-extensions, tqdm, tornado, toml, tenacity, sniffio, smmap, six, rpds-py, pyyaml, pyparsing, pygments, pycparser, pyasn1, pyarrow, protobuf, pillow, packaging, ormsgpack, orjson, numpy, narwhals, mdurl, MarkupSafe, kiwisolver, jsonpointer, idna, h11, fonttools, dockerfile-parse, distro, cycler, click, charset_normalizer, certifi, cachetools, bracex, blinker, attrs, annotated-types, wcmatch, typing-inspection, rsa, requests, referencing, python-dateutil, pydantic-core, pyasn1-modules, proto-plus, markdown-it-py, jsonpatch, jinja2, httplib2, httpcore, grpcio, googleapis-common-protos, gitdb, contourpy, cffi, anyio, rich, requests-toolbelt, pydeck, pydantic, pandas, matplotlib, jsonschema-specifications, httpx, grpcio-status, gitpython, cryptography, seaborn, langsmith, langgraph-sdk, jsonschema, google-auth, e2b, langchain-core, google-auth-httplib2, google-api-core, e2b-code-interpreter, altair, streamlit, langgraph-checkpoint, google-genai, google-api-python-client, langgraph-prebuilt, langchain-google-genai, google-ai-generativelanguage, langgraph, google-generativeai, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 26.0\n",
            "    Uninstalling packaging-26.0:\n",
            "      Successfully uninstalled packaging-26.0\n",
            "\n",
            "Successfully installed MarkupSafe-3.0.3 altair-6.0.0 annotated-types-0.7.0 anyio-4.12.1 attrs-25.4.0 blinker-1.9.0 bracex-2.6 cachetools-6.2.6 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 contourpy-1.3.3 cryptography-46.0.4 cycler-0.12.1 distro-1.9.0 dockerfile-parse-2.0.1 e2b-2.12.1 e2b-code-interpreter-2.4.1 filetype-1.2.0 fonttools-4.61.1 gitdb-4.0.12 gitpython-3.1.46 google-ai-generativelanguage-0.6.15 google-api-core-2.29.0 google-api-python-client-2.188.0 google-auth-2.48.0 google-auth-httplib2-0.3.0 google-genai-1.60.0 google-generativeai-0.8.6 googleapis-common-protos-1.72.0 grpcio-1.76.0 grpcio-status-1.71.2 h11-0.16.0 httpcore-1.0.9 httplib2-0.31.2 httpx-0.28.1 idna-3.11 jinja2-3.1.6 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 kiwisolver-1.4.9 langchain-1.2.7 langchain-core-1.2.7 langchain-google-genai-4.2.0 langgraph-1.0.7 langgraph-checkpoint-4.0.0 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.3 langsmith-0.6.6 markdown-it-py-4.0.0 matplotlib-3.10.8 mdurl-0.1.2 narwhals-2.15.0 numpy-2.4.1 orjson-3.11.6 ormsgpack-1.12.2 packaging-25.0 pandas-2.3.3 pillow-11.3.0 proto-plus-1.27.0 protobuf-5.29.5 pyarrow-23.0.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 pycparser-3.0 pydantic-2.12.5 pydantic-core-2.41.5 pydeck-0.9.1 pygments-2.19.2 pyparsing-3.3.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 referencing-0.37.0 requests-2.32.5 requests-toolbelt-1.0.0 rich-14.3.1 rpds-py-0.30.0 rsa-4.9.1 seaborn-0.13.2 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 streamlit-1.53.1 tenacity-9.1.2 toml-0.10.2 tornado-6.5.4 tqdm-4.67.1 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.3 uritemplate-4.2.0 urllib3-2.6.3 uuid-utils-0.14.0 watchdog-6.0.0 wcmatch-10.1 websockets-15.0.1 xxhash-3.6.0 zstandard-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"/content/.streamlit\", exist_ok=True)\n",
        "\n",
        "with open(\"/content/.streamlit/secrets.toml\", \"w\") as f:\n",
        "    f.write(\n",
        "        'GOOGLE_API_KEY=\"PASTE_YOUR_API_KEY\"\\n'\n",
        "        'E2B_API_KEY=\"PASTE_YOUR_API_KEY\"\\n'\n",
        "    )\n",
        "\n",
        "print(\"Saved keys to /content/.streamlit/secrets.toml\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkFDAS3SLoZs",
        "outputId": "59d6f223-34d7-4911-c17f-4da3680ef445"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved keys to /content/.streamlit/secrets.toml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/ads_venv/bin/python -m pip install -U google-generativeai langchain-google-genai langchain langchain-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzcdnuTqOVNo",
        "outputId": "f136ef92-5f87-45c0-b5e2-485e4e754704"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in ./ads_venv/lib/python3.12/site-packages (0.8.6)\n",
            "Requirement already satisfied: langchain-google-genai in ./ads_venv/lib/python3.12/site-packages (4.2.0)\n",
            "Requirement already satisfied: langchain in ./ads_venv/lib/python3.12/site-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-core in ./ads_venv/lib/python3.12/site-packages (1.2.7)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (2.188.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (2.48.0)\n",
            "Requirement already satisfied: protobuf in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (2.12.5)\n",
            "Requirement already satisfied: tqdm in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in ./ads_venv/lib/python3.12/site-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./ads_venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./ads_venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in ./ads_venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./ads_venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./ads_venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./ads_venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: cryptography>=38.0.3 in ./ads_venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (46.0.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./ads_venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./ads_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./ads_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./ads_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./ads_venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in ./ads_venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-google-genai) (1.60.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (0.6.6)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./ads_venv/lib/python3.12/site-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in ./ads_venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in ./ads_venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in ./ads_venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./ads_venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in ./ads_venv/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in ./ads_venv/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./ads_venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./ads_venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in ./ads_venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.6)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./ads_venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in ./ads_venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./ads_venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in ./ads_venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in ./ads_venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in ./ads_venv/lib/python3.12/site-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in ./ads_venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in ./ads_venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in ./ads_venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in ./ads_venv/lib/python3.12/site-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in ./ads_venv/lib/python3.12/site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Requirement already satisfied: cffi>=2.0.0 in ./ads_venv/lib/python3.12/site-packages (from cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai) (2.0.0)\n",
            "Requirement already satisfied: pycparser in ./ads_venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth>=2.15.0->google-generativeai) (3.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./ads_venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.31.2)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./ads_venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./ads_venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in ./ads_venv/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "/content/ads_venv/bin/python - <<'PY'\n",
        "import tomllib\n",
        "import google.generativeai as genai\n",
        "\n",
        "secrets = tomllib.load(open(\"/content/.streamlit/secrets.toml\",\"rb\"))\n",
        "genai.configure(api_key=secrets[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "print(\"Models supporting generateContent:\\n\")\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in getattr(m, \"supported_generation_methods\", []):\n",
        "        print(m.name)\n",
        "PY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79KzhQPcOYy7",
        "outputId": "40264773-0ab3-4817-fed7-8fb1012908d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models supporting generateContent:\n",
            "\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<stdin>:2: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "# End-to-end patched for:\n",
        "# - Gemini models: supports models/* ids + fallback; normalizes list content -> string\n",
        "# - E2B e2b-code-interpreter==2.4.1: MUST use Sandbox.create()\n",
        "# - Colab-friendly: run via /content/ads_venv/bin/python -m streamlit run app.py\n",
        "%%writefile /content/app.py\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import base64\n",
        "import tempfile\n",
        "import traceback\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import streamlit as st\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "\n",
        "# E2B (your working path)\n",
        "try:\n",
        "    from e2b_code_interpreter.code_interpreter_sync import Sandbox as E2BSandbox  # type: ignore\n",
        "    E2B_BACKEND = \"e2b_code_interpreter.code_interpreter_sync.Sandbox\"\n",
        "except Exception:\n",
        "    from e2b_code_interpreter import Sandbox as E2BSandbox  # type: ignore\n",
        "    E2B_BACKEND = \"e2b_code_interpreter.Sandbox\"\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Page config\n",
        "# ----------------------------\n",
        "st.set_page_config(page_title=\"Autonomous Data Science Agent\", layout=\"wide\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Secrets / Config\n",
        "# ----------------------------\n",
        "def get_secret(name: str) -> Optional[str]:\n",
        "    try:\n",
        "        v = st.secrets.get(name)  # type: ignore[attr-defined]\n",
        "        if v:\n",
        "            return str(v)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return os.getenv(name)\n",
        "\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in st.session_state:\n",
        "    st.session_state.GOOGLE_API_KEY = get_secret(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if \"E2B_API_KEY\" not in st.session_state:\n",
        "    st.session_state.E2B_API_KEY = get_secret(\"E2B_API_KEY\")\n",
        "\n",
        "# Models you confirmed are available for generateContent\n",
        "SUPPORTED_MODELS = [\n",
        "    \"models/gemini-flash-latest\",\n",
        "    \"models/gemini-pro-latest\",\n",
        "    \"models/gemini-2.5-flash\",\n",
        "    \"models/gemini-2.5-pro\",\n",
        "    \"models/gemini-2.0-flash\",\n",
        "]\n",
        "\n",
        "if \"GEMINI_MODEL\" not in st.session_state:\n",
        "    st.session_state.GEMINI_MODEL = \"models/gemini-flash-latest\"\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "CODE_BLOCK_RE = re.compile(r\"```(?:python)?\\s*(.*?)```\", re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "\n",
        "def llm_content_to_text(content: Any) -> str:\n",
        "    \"\"\"\n",
        "    Gemini/LangChain sometimes returns content as a LIST of parts.\n",
        "    Convert to a single string safe for regex parsing.\n",
        "    \"\"\"\n",
        "    if content is None:\n",
        "        return \"\"\n",
        "    if isinstance(content, str):\n",
        "        return content\n",
        "    if isinstance(content, list):\n",
        "        parts: List[str] = []\n",
        "        for p in content:\n",
        "            if p is None:\n",
        "                continue\n",
        "            if isinstance(p, str):\n",
        "                parts.append(p)\n",
        "            elif isinstance(p, dict):\n",
        "                # common shapes: {\"text\": \"...\"} or {\"type\":\"text\",\"text\":\"...\"}\n",
        "                if \"text\" in p and isinstance(p[\"text\"], str):\n",
        "                    parts.append(p[\"text\"])\n",
        "                else:\n",
        "                    parts.append(str(p))\n",
        "            else:\n",
        "                # objects with .text, etc.\n",
        "                t = getattr(p, \"text\", None)\n",
        "                if isinstance(t, str):\n",
        "                    parts.append(t)\n",
        "                else:\n",
        "                    parts.append(str(p))\n",
        "        return \"\".join(parts)\n",
        "    return str(content)\n",
        "\n",
        "\n",
        "def extract_code_and_text(model_output: str) -> Tuple[str, str]:\n",
        "    matches = CODE_BLOCK_RE.findall(model_output or \"\")\n",
        "    code = matches[0].strip() if matches else \"\"\n",
        "    text = CODE_BLOCK_RE.sub(\"\", model_output or \"\").strip()\n",
        "    if not text and code:\n",
        "        text = \"Executed the analysis in the sandbox. See outputs below.\"\n",
        "    return code, text\n",
        "\n",
        "\n",
        "def safe_filename(name: str) -> str:\n",
        "    name = name or \"dataset.csv\"\n",
        "    return re.sub(r\"[^A-Za-z0-9_.-]\", \"_\", name)\n",
        "\n",
        "\n",
        "def build_system_prompt(remote_path: str) -> str:\n",
        "    return f\"\"\"\n",
        "You are an Expert Python Data Scientist. You have access to a dataset at path: {remote_path}\n",
        "\n",
        "Rules:\n",
        "- Be concise. Avoid conversational filler (e.g., \"Here is the code\").\n",
        "- Always read the dataset using pandas: df = pd.read_csv(r\"{remote_path}\")\n",
        "- Use pandas, matplotlib, seaborn as needed.\n",
        "- If a chart is relevant, generate it and ALWAYS call plt.show() so it is captured.\n",
        "- Return your response in TWO parts:\n",
        "  1) A short answer (bullets are fine).\n",
        "  2) ONE executable Python code block fenced as ```python ... ``` (no extra code blocks).\n",
        "- The code must be runnable as-is in a fresh Python environment.\n",
        "\"\"\".strip()\n",
        "\n",
        "\n",
        "def normalize_logs(v: Any) -> str:\n",
        "    \"\"\"E2B 2.4.1 logs are lists; normalize to string.\"\"\"\n",
        "    if v is None:\n",
        "        return \"\"\n",
        "    if isinstance(v, str):\n",
        "        return v\n",
        "    if isinstance(v, list):\n",
        "        try:\n",
        "            return \"\".join(map(str, v))\n",
        "        except Exception:\n",
        "            return \"\\n\".join([repr(x) for x in v])\n",
        "    return str(v)\n",
        "\n",
        "\n",
        "def _b64_to_bytes(s: str) -> Optional[bytes]:\n",
        "    try:\n",
        "        return base64.b64decode(s)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def coerce_image_to_bytes(obj: Any) -> Optional[bytes]:\n",
        "    try:\n",
        "        if obj is None:\n",
        "            return None\n",
        "\n",
        "        if isinstance(obj, (bytes, bytearray)):\n",
        "            return bytes(obj)\n",
        "\n",
        "        if isinstance(obj, str):\n",
        "            return _b64_to_bytes(obj)\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            for k in (\"png\", \"data\", \"base64\"):\n",
        "                v = obj.get(k)\n",
        "                if isinstance(v, (bytes, bytearray)):\n",
        "                    return bytes(v)\n",
        "                if isinstance(v, str):\n",
        "                    b = _b64_to_bytes(v)\n",
        "                    if b:\n",
        "                        return b\n",
        "\n",
        "        for attr in (\"png\", \"data\", \"base64\"):\n",
        "            if hasattr(obj, attr):\n",
        "                v = getattr(obj, attr)\n",
        "                if isinstance(v, (bytes, bytearray)):\n",
        "                    return bytes(v)\n",
        "                if isinstance(v, str):\n",
        "                    b = _b64_to_bytes(v)\n",
        "                    if b:\n",
        "                        return b\n",
        "\n",
        "        # PIL fallback\n",
        "        try:\n",
        "            from PIL import Image  # type: ignore\n",
        "\n",
        "            if isinstance(obj, Image.Image):\n",
        "                buf = io.BytesIO()\n",
        "                obj.save(buf, format=\"PNG\")\n",
        "                return buf.getvalue()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# E2B Sandbox Manager (E2B 2.4.1: Sandbox.create() only)\n",
        "# ----------------------------\n",
        "class SandboxHandler:\n",
        "    def __init__(self, e2b_api_key: str):\n",
        "        if not e2b_api_key:\n",
        "            raise ValueError(\"E2B_API_KEY is missing.\")\n",
        "\n",
        "        os.environ[\"E2B_API_KEY\"] = e2b_api_key\n",
        "\n",
        "        if not (hasattr(E2BSandbox, \"create\") and callable(getattr(E2BSandbox, \"create\"))):\n",
        "            raise RuntimeError(f\"{E2B_BACKEND} does not expose Sandbox.create().\")\n",
        "\n",
        "        self.sandbox = E2BSandbox.create()\n",
        "        self.init_mode = \"Sandbox.create()\"\n",
        "        self.backend = E2B_BACKEND\n",
        "\n",
        "        try:\n",
        "            self.sandbox.run_code(\n",
        "                \"import os\\n\"\n",
        "                \"os.makedirs('/home/user/data', exist_ok=True)\\n\"\n",
        "                \"print('Sandbox ready')\\n\"\n",
        "            )\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def upload_file(self, uploaded_file) -> str:\n",
        "        if uploaded_file is None:\n",
        "            raise ValueError(\"No file provided.\")\n",
        "        data = uploaded_file.getvalue()\n",
        "        if not data:\n",
        "            raise ValueError(\"Uploaded file is empty.\")\n",
        "\n",
        "        fname = safe_filename(getattr(uploaded_file, \"name\", \"dataset.csv\"))\n",
        "        remote_path = f\"/home/user/data/{fname}\"\n",
        "\n",
        "        # E2B 2.4.1 supports files.write(path, bytes)\n",
        "        self.sandbox.files.write(remote_path, data)  # type: ignore[attr-defined]\n",
        "        return remote_path\n",
        "\n",
        "    def run_code(self, code: str) -> Dict[str, Any]:\n",
        "        if not code or not code.strip():\n",
        "            return {\"stdout\": \"\", \"stderr\": \"No code to execute.\", \"images\": [], \"raw\": None}\n",
        "\n",
        "        try:\n",
        "            execution = self.sandbox.run_code(code)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"stdout\": \"\",\n",
        "                \"stderr\": f\"Sandbox execution failed: {e}\\n\\n{traceback.format_exc()}\",\n",
        "                \"images\": [],\n",
        "                \"raw\": None,\n",
        "            }\n",
        "\n",
        "        stdout, stderr = \"\", \"\"\n",
        "        images: List[bytes] = []\n",
        "\n",
        "        try:\n",
        "            logs = getattr(execution, \"logs\", None)\n",
        "            if logs is not None:\n",
        "                stdout = normalize_logs(getattr(logs, \"stdout\", \"\"))\n",
        "                stderr = normalize_logs(getattr(logs, \"stderr\", \"\"))\n",
        "            else:\n",
        "                stdout = normalize_logs(getattr(execution, \"stdout\", \"\"))\n",
        "                stderr = normalize_logs(getattr(execution, \"stderr\", \"\"))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            for img in (getattr(execution, \"images\", None) or []):\n",
        "                b = coerce_image_to_bytes(img)\n",
        "                if b:\n",
        "                    images.append(b)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        try:\n",
        "            for r in (getattr(execution, \"results\", None) or []):\n",
        "                b = coerce_image_to_bytes(r)\n",
        "                if b:\n",
        "                    images.append(b)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return {\"stdout\": stdout, \"stderr\": stderr, \"images\": images, \"raw\": execution}\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Cached resources\n",
        "# ----------------------------\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def get_sandbox_handler(e2b_key: str) -> SandboxHandler:\n",
        "    return SandboxHandler(e2b_key)\n",
        "\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def get_llm(google_key: str, model_name: str) -> ChatGoogleGenerativeAI:\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=model_name,\n",
        "        temperature=0.2,\n",
        "        google_api_key=google_key,\n",
        "    )\n",
        "\n",
        "\n",
        "def invoke_with_model_fallback(\n",
        "    google_key: str,\n",
        "    model_name: str,\n",
        "    messages: List[Any],\n",
        "    fallback_model: str = \"models/gemini-flash-latest\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Always returns TEXT (string). Handles Gemini content being list-of-parts.\n",
        "    Also retries on model 404/NOT_FOUND using fallback model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        llm = get_llm(google_key, model_name)\n",
        "        resp = llm.invoke(messages)\n",
        "        return llm_content_to_text(getattr(resp, \"content\", resp))\n",
        "    except Exception as e:\n",
        "        msg = str(e)\n",
        "        if (\"404\" in msg) or (\"NOT_FOUND\" in msg) or (\"not found\" in msg.lower()):\n",
        "            llm_fb = get_llm(google_key, fallback_model)\n",
        "            resp2 = llm_fb.invoke(messages)\n",
        "            return llm_content_to_text(getattr(resp2, \"content\", resp2))\n",
        "        raise\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Session state init\n",
        "# ----------------------------\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "if \"remote_path\" not in st.session_state:\n",
        "    st.session_state.remote_path = None\n",
        "if \"uploaded_filename\" not in st.session_state:\n",
        "    st.session_state.uploaded_filename = None\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Sidebar UI\n",
        "# ----------------------------\n",
        "with st.sidebar:\n",
        "    st.header(\"Configuration\")\n",
        "\n",
        "    st.text_input(\"GOOGLE_API_KEY\", type=\"password\",\n",
        "                  value=st.session_state.GOOGLE_API_KEY or \"\", key=\"GOOGLE_API_KEY\")\n",
        "    st.text_input(\"E2B_API_KEY\", type=\"password\",\n",
        "                  value=st.session_state.E2B_API_KEY or \"\", key=\"E2B_API_KEY\")\n",
        "\n",
        "    st.selectbox(\n",
        "        \"Gemini model\",\n",
        "        options=SUPPORTED_MODELS,\n",
        "        index=SUPPORTED_MODELS.index(st.session_state.GEMINI_MODEL)\n",
        "        if st.session_state.GEMINI_MODEL in SUPPORTED_MODELS else 0,\n",
        "        key=\"GEMINI_MODEL\",\n",
        "    )\n",
        "\n",
        "    if not st.session_state.GOOGLE_API_KEY:\n",
        "        st.warning(\"Missing GOOGLE_API_KEY (st.secrets or env).\")\n",
        "    else:\n",
        "        st.success(\"GOOGLE_API_KEY loaded.\")\n",
        "\n",
        "    if not st.session_state.E2B_API_KEY:\n",
        "        st.warning(\"Missing E2B_API_KEY (st.secrets or env).\")\n",
        "    else:\n",
        "        st.success(\"E2B_API_KEY loaded.\")\n",
        "\n",
        "    st.caption(f\"E2B backend: `{E2B_BACKEND}`\")\n",
        "\n",
        "    if st.button(\"Reset sandbox/cache\"):\n",
        "        try:\n",
        "            st.cache_resource.clear()\n",
        "        except Exception:\n",
        "            pass\n",
        "        st.session_state.remote_path = None\n",
        "        st.session_state.uploaded_filename = None\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "\n",
        "    st.divider()\n",
        "    st.subheader(\"Dataset Upload\")\n",
        "\n",
        "    uploaded = st.file_uploader(\"Upload a CSV file\", type=[\"csv\"])\n",
        "    if uploaded is not None:\n",
        "        try:\n",
        "            if not st.session_state.E2B_API_KEY:\n",
        "                raise RuntimeError(\"E2B_API_KEY is missing.\")\n",
        "            sb = get_sandbox_handler(st.session_state.E2B_API_KEY)\n",
        "            st.caption(f\"E2B init: `{sb.init_mode}`\")\n",
        "\n",
        "            if st.session_state.uploaded_filename != uploaded.name or st.session_state.remote_path is None:\n",
        "                remote_path = sb.upload_file(uploaded)\n",
        "                st.session_state.remote_path = remote_path\n",
        "                st.session_state.uploaded_filename = uploaded.name\n",
        "                st.success(\"Dataset Uploaded Successfully\")\n",
        "                st.caption(f\"Sandbox path: `{remote_path}`\")\n",
        "                st.session_state.messages = []\n",
        "        except Exception as e:\n",
        "            st.error(f\"Upload failed: {e}\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Main UI\n",
        "# ----------------------------\n",
        "st.title(\"🤖 Autonomous Data Science Agent\")\n",
        "\n",
        "if not st.session_state.remote_path:\n",
        "    st.info(\"Upload a CSV in the sidebar to begin.\")\n",
        "    st.stop()\n",
        "\n",
        "if not st.session_state.GOOGLE_API_KEY:\n",
        "    st.error(\"GOOGLE_API_KEY is required.\")\n",
        "    st.stop()\n",
        "\n",
        "if not st.session_state.E2B_API_KEY:\n",
        "    st.error(\"E2B_API_KEY is required.\")\n",
        "    st.stop()\n",
        "\n",
        "# Render chat history\n",
        "for msg in st.session_state.messages:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "user_query = st.chat_input(\"Ask a question about your dataset (EDA, plots, modeling, etc.)\")\n",
        "\n",
        "if user_query:\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_query})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_query)\n",
        "\n",
        "    remote_path = st.session_state.remote_path\n",
        "    system_prompt = build_system_prompt(remote_path)\n",
        "\n",
        "    chosen_model = st.session_state.GEMINI_MODEL\n",
        "    fallback_model = \"models/gemini-flash-latest\"\n",
        "\n",
        "    sb = get_sandbox_handler(st.session_state.E2B_API_KEY)\n",
        "\n",
        "    lc_messages: List[Any] = [SystemMessage(content=system_prompt)]\n",
        "    for m in st.session_state.messages:\n",
        "        lc_messages.append(\n",
        "            HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"])\n",
        "        )\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"🤖 Analyzing data...\"):\n",
        "            # 1) Gemini -> (text+code)\n",
        "            try:\n",
        "                model_output = invoke_with_model_fallback(\n",
        "                    st.session_state.GOOGLE_API_KEY,\n",
        "                    chosen_model,\n",
        "                    lc_messages,\n",
        "                    fallback_model=fallback_model,\n",
        "                )\n",
        "            except Exception as e:\n",
        "                st.error(f\"Gemini request failed: {e}\")\n",
        "                st.stop()\n",
        "\n",
        "            code, assistant_text = extract_code_and_text(model_output)\n",
        "\n",
        "            # Force code if missing\n",
        "            if not code.strip():\n",
        "                force = (\n",
        "                    \"Return ONLY one executable Python code block fenced as ```python ... ```.\\n\"\n",
        "                    f\"Dataset path: {remote_path}\\n\"\n",
        "                    f\"Must include: df = pd.read_csv(r\\\"{remote_path}\\\")\\n\"\n",
        "                    \"If you generate plots, call plt.show().\"\n",
        "                )\n",
        "                model_output = invoke_with_model_fallback(\n",
        "                    st.session_state.GOOGLE_API_KEY,\n",
        "                    chosen_model,\n",
        "                    lc_messages + [HumanMessage(content=force)],\n",
        "                    fallback_model=fallback_model,\n",
        "                )\n",
        "                code, assistant_text2 = extract_code_and_text(model_output)\n",
        "                if assistant_text2:\n",
        "                    assistant_text = assistant_text2\n",
        "\n",
        "            # 2) Execute + self-correct loop\n",
        "            final_text = assistant_text\n",
        "            final_code = code\n",
        "            final_stdout = \"\"\n",
        "            final_stderr = \"\"\n",
        "            final_images: List[bytes] = []\n",
        "\n",
        "            retries = 0\n",
        "            last_exec: Optional[Dict[str, Any]] = None\n",
        "\n",
        "            while retries < 3:\n",
        "                last_exec = sb.run_code(final_code)\n",
        "                final_stdout = last_exec.get(\"stdout\", \"\") or \"\"\n",
        "                final_stderr = last_exec.get(\"stderr\", \"\") or \"\"\n",
        "                final_images = last_exec.get(\"images\", []) or []\n",
        "\n",
        "                if final_stderr.strip():\n",
        "                    retries += 1\n",
        "                    fix_prompt = (\n",
        "                        \"You got this error. Fix the code and try again.\\n\\n\"\n",
        "                        f\"{final_stderr}\\n\\n\"\n",
        "                        \"Return ONLY one executable Python code block fenced as ```python ... ```.\\n\"\n",
        "                        f\"Dataset path: {remote_path}\\n\"\n",
        "                        f\"Must include: df = pd.read_csv(r\\\"{remote_path}\\\")\\n\"\n",
        "                        \"If you generate plots, call plt.show().\"\n",
        "                    )\n",
        "                    fix_out = invoke_with_model_fallback(\n",
        "                        st.session_state.GOOGLE_API_KEY,\n",
        "                        chosen_model,\n",
        "                        [SystemMessage(content=system_prompt), *lc_messages[1:], AIMessage(content=model_output), HumanMessage(content=fix_prompt)],\n",
        "                        fallback_model=fallback_model,\n",
        "                    )\n",
        "                    code2, _ = extract_code_and_text(fix_out)\n",
        "                    if code2.strip():\n",
        "                        final_code = code2\n",
        "                        model_output = fix_out\n",
        "                        continue\n",
        "                    break\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        st.markdown(final_text)\n",
        "\n",
        "        if final_images:\n",
        "            for i, b in enumerate(final_images, start=1):\n",
        "                st.image(b, caption=f\"Chart {i}\", use_container_width=True)\n",
        "\n",
        "        with st.expander(\"See executed code\"):\n",
        "            st.code(final_code or \"# (no code)\", language=\"python\")\n",
        "            if final_stdout.strip():\n",
        "                st.subheader(\"stdout\")\n",
        "                st.code(final_stdout, language=\"text\")\n",
        "            if final_stderr.strip():\n",
        "                st.subheader(\"stderr\")\n",
        "                st.code(final_stderr, language=\"text\")\n",
        "\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": final_text})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNDo8dwyL1_z",
        "outputId": "ad7cd572-f0a1-4733-d913-bd350bbf1648"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "pkill -f \"streamlit run /content/app.py\" || true\n",
        "\n",
        "nohup /content/ads_venv/bin/python -m streamlit run /content/app.py \\\n",
        "  --server.address 0.0.0.0 --server.port 8501 \\\n",
        "  --server.enableCORS false --server.enableXsrfProtection false \\\n",
        "  --browser.gatherUsageStats false \\\n",
        "  > /content/streamlit.log 2>&1 &"
      ],
      "metadata": {
        "id": "RYgeoC4YL6nW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 80 /content/streamlit.log\n",
        "!curl -I http://localhost:8501 | head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HVGWPxKL8__",
        "outputId": "84a297eb-c2e6-4c6b-d2b7-44b55dab4325"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  URL: http://0.0.0.0:8501\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0  1522    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "HTTP/1.1 200 OK\n",
            "Server: TornadoServer/6.5.4\n",
            "Content-Type: text/html\n",
            "Date: Thu, 29 Jan 2026 15:48:54 GMT\n",
            "Accept-Ranges: bytes\n",
            "Etag: \"7d9e795beb02d5dcdf74cc38d352342ed3b6d5c2b91e29e46d25d795c1aade0dc6df0aa9c6141ebf9d712fd99d3cb1aaf9ac2b3dc74acd445e3c631dbfcc847b\"\n",
            "Last-Modified: Thu, 29 Jan 2026 15:48:01 GMT\n",
            "Cache-Control: no-cache\n",
            "Content-Length: 1522\n",
            "Vary: Accept-Encoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import socket, subprocess, time, re\n",
        "\n",
        "def get_free_port():\n",
        "    s = socket.socket()\n",
        "    s.bind((\"\", 0))\n",
        "    port = s.getsockname()[1]\n",
        "    s.close()\n",
        "    return port\n",
        "\n",
        "PORT = get_free_port()\n",
        "print(\"Using port:\", PORT)\n",
        "\n",
        "# Kill previous runs (safe)\n",
        "subprocess.run(\"pkill -f 'streamlit run /content/app.py' || true\", shell=True)\n",
        "subprocess.run(\"pkill -f 'cloudflared tunnel --url' || true\", shell=True)\n",
        "\n",
        "# Start Streamlit in background\n",
        "subprocess.Popen(\n",
        "    [\"/content/ads_venv/bin/python\", \"-m\", \"streamlit\", \"run\", \"/content/app.py\",\n",
        "     \"--server.address\", \"0.0.0.0\",\n",
        "     \"--server.port\", str(PORT),\n",
        "     \"--server.enableCORS\", \"false\",\n",
        "     \"--server.enableXsrfProtection\", \"false\"],\n",
        "    stdout=open(\"/content/streamlit.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT\n",
        ")\n",
        "\n",
        "# Wait until Streamlit is reachable\n",
        "for _ in range(30):\n",
        "    r = subprocess.run([\"bash\", \"-lc\", f\"curl -s -o /dev/null -w '%{{http_code}}' http://localhost:{PORT}\"],\n",
        "                       capture_output=True, text=True)\n",
        "    if r.stdout.strip() in (\"200\", \"302\"):\n",
        "        print(\"Streamlit is up.\")\n",
        "        break\n",
        "    time.sleep(1)\n",
        "else:\n",
        "    print(\"Streamlit did not start. Check /content/streamlit.log\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv-Qvp05bAYP",
        "outputId": "84dac6ef-0ae3-41e7-e6da-f5c43d6c8764"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using port: 42185\n",
            "Streamlit is up.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 12345 with the printed port\n",
        "!/usr/local/bin/cloudflared tunnel --url http://localhost:42185 --no-autoupdate --loglevel info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp1rKBt4cw9v",
        "outputId": "a465f696-2061-427f-e524-38acc039c9eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90m2026-01-29T15:51:48Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2026-01-29T15:51:48Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m |  https://performer-deferred-rec-belfast.trycloudflare.com                                  |\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Version 2026.1.2 (Checksum e157c54e929cc289cbd53860453168c2fe3439eb55e2e965a56579252585d9c1)\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.11, GoArch: amd64\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 loglevel:info no-autoupdate:true protocol:quic url:http://localhost:42185]\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 32cdea01-8eeb-495a-87fb-9cd727ac7d3d\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol quic\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel connection curve preferences: [X25519MLKEM768 CurveP256] \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "2026/01/29 15:51:52 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 7168 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details.\n",
            "\u001b[90m2026-01-29T15:51:52Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m323b06da-2f1c-4600-a3db-5a6847b5ee84 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233 \u001b[36mlocation=\u001b[0mlax01 \u001b[36mprotocol=\u001b[0mquic\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[32mINF\u001b[0m Initiating graceful shutdown due to signal interrupt ...\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to run the datagram handler \u001b[31merror=\u001b[0m\u001b[31m\"context canceled\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m failed to serve tunnel connection \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Serve tunnel error \u001b[31merror=\u001b[0m\u001b[31m\"accept stream listener encountered a failure while serving\"\u001b[0m \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[32mINF\u001b[0m Retrying connection in up to 1s \u001b[36mconnIndex=\u001b[0m0 \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.200.233\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m Connection terminated \u001b[36mconnIndex=\u001b[0m0\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[1m\u001b[31mERR\u001b[0m\u001b[0m no more connections active and exiting\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[32mINF\u001b[0m Tunnel server stopped\n",
            "\u001b[90m2026-01-29T16:15:57Z\u001b[0m \u001b[32mINF\u001b[0m Metrics server stopped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7Pcid6Zc51_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}